
# Monocular Depth Estimation Literature Reviews

This is a set of brief reviews in the **Monocular Depth Estimation** area on most recent research papers in the filed. 

Monocular Depth Estimation is the task of estimating the depth value (distance relative to the camera) of each pixel given a single (monocular) RGB image. This challenging task is a key prerequisite for determining scene understanding for applications such as 3D scene reconstruction, autonomous driving, and AR.



## Pure MDE

Here, summarize the investigations in the new useful MDE softwares which are included in a research project. I mean they have the both open-source code and the paper.

After presenting the aforementioned data about each paper, answer to the following questions in your review:

- Explain an outline of the method

- Describe the performance in terms of depth estimation quality, FPS, etc. such that makes it comparable with the rest of the similar works

*TIP:* Here, we need to make a list of the open-source MDE state-of-the-art. Make sure that the papers you list all have a source code link. We'll need to deploy one, or a couple of the best ones.
To complete this part, see the following link(s):

[link](https://paperswithcode.com/task/monocular-depth-estimation)

And also you can do your own investigation to get the most valid softwares and enhance the list.


## MDE for SLAM

Here, talk about the research projects which their output was a SLAM base-on, or aided-by the MDE.
In your review, answer to the following questions:

- Explain an outline of the method

- Is there any sensor fusion or data fusion? What are the sensors? Is the system V-INS? Just Visual? Or something else?

- If used, how was the neural network architecture?

- Give a criteria of the calculational ability (FPS in terms of processor)

- In what range of cases, and how, is the system implemented? What were the mission and mission specifications?

- Is the system based on a flying robot platform? If yes, what was the platform? 


### Pseudo RGB-D for Self-improving Monocular SLAM and Depth Prediction

[Link to the Paper](https://drive.google.com/file/d/1SH6aLfpXGzQPGlCQWy0Moy6ERl6ExXaH/view?usp=sharing)

[Link to the Source Code]()

**Authors:** 

**Date:** 

**Journal or Conference:** ...

####Review:

Type a paragraph

####Answers:

Type the answers separately


### SDF-SLAM: A Deep Learning Based Highly Accurate SLAM Using Monocular Camera Aiming at Indoor Map Reconstruction With Semantic and Depth Fusion

[Link to the Paper]()

[Link to the Source Code]()

**Authors:** 

**Date:** 

**Journal or Conference:** ...

####Review:

Type a paragraph

####Answers:

Type the answers separately






## MDE for VIO and Navigation

Summarize the works concentrating on obtaining navigation data and visual odometry.

In your review, answer to the following questions:

- Explain an outline of the method

- Is there any sensor fusion or data fusion? What are the sensors? Is the system V-INS? Just Visual? Or something else?

- If used, how was the neural network architecture?

- Give a criteria of the calculational ability (FPS in terms of processor)

- In what range of cases, and how, is the system implemented? What were the mission and mission specifications?

- Is the system based on a flying robot platform? If yes, what was the platform? 


### Towards Scale-Aware, Robust, and Generalizable Unsupervised Monocular Depth Estimation by Integrating IMU Motion Dynamics

[Link to the Paper]()

[Link to the Source Code]()

**Authors:** 

**Date:** 

**Journal or Conference:** ...

####Review:

Type a paragraph

####Answers:

Type the answers separately


### M4Depth: Monocular depth estimation for autonomous vehicles in unseen environments

[Link to the Paper]()

[Link to the Source Code](https://github.com/michael-fonder/M4Depth)

**Authors:** 

**Date:** 

**Journal or Conference:** ...

####Review:

Type a paragraph

####Answers:

Type the answers separately


### Bayesian cue integration of structure from motion and CNN‑based monocular depth estimation for autonomous robot navigation

[Link to the Paper](https://drive.google.com/file/d/1s-s11aPrmPC9uOqdnJ91yBntFpcqAdvS/view?usp=sharing)

[Link to the Source Code]()

**Authors:** 

**Date:** 

**Journal or Conference:** ...

####Review:

Type a paragraph

####Answers:

Type the answers separately


### SelfVIO: Self-supervised deep monocular Visual–Inertial Odometry and depth estimation

[Link to the Paper]()

[Link to the Source Code]()

**Authors:** 

**Date:** 

**Journal or Conference:** ...

####Review:

Type a paragraph

####Answers:

Type the answers separately


### Multi-Sensor Fusion Self-Supervised Deep Odometry and Depth Estimation

[Link to the Paper]()

[Link to the Source Code]()

**Authors:** 

**Date:** 

**Journal or Conference:** ...

####Review:

Type a paragraph

####Answers:

Type the answers separately


### On deep learning techniques to boost monocular depth estimation for autonomous navigation

[Link to the Paper]()

[Link to the Source Code]()

**Authors:** 

**Date:** 

**Journal or Conference:** ...

####Review:

Type a paragraph

####Answers:

Type the answers separately


### Joint Estimation of Depth and Pose with IMU-assisted Photometric Loss

[Link to the Paper]()

[Link to the Source Code]()

**Authors:** 

**Date:** 

**Journal or Conference:** ...

####Review:

Type a paragraph

####Answers:

Type the answers separately

